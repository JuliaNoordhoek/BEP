{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bad8915-569c-4f63-9fa1-25d813e796c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a183ce09-bfb8-4e4c-b774-5dffc2bfdef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inlezen van de dataset\n",
    "df = pd.read_excel(\"C:/Users/20201954/Desktop/data/merged_data_MRI_IQR.xlsx\")\n",
    "df.replace(',', '.', regex=True, inplace=True)\n",
    "df = df.apply(pd.to_numeric, errors='coerce')\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "790d0ba2-6c40-405a-b475-0d136200a3d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20201954\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0794 - loss: 3.3921 - val_accuracy: 0.2358 - val_loss: 2.7876\n",
      "Epoch 2/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3150 - loss: 2.5843 - val_accuracy: 0.4017 - val_loss: 2.2337\n",
      "Epoch 3/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4577 - loss: 2.0726 - val_accuracy: 0.5036 - val_loss: 1.8660\n",
      "Epoch 4/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5476 - loss: 1.7072 - val_accuracy: 0.5415 - val_loss: 1.6304\n",
      "Epoch 5/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6084 - loss: 1.4511 - val_accuracy: 0.5575 - val_loss: 1.4605\n",
      "Epoch 6/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6510 - loss: 1.2726 - val_accuracy: 0.5852 - val_loss: 1.3500\n",
      "Epoch 7/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6695 - loss: 1.1602 - val_accuracy: 0.6041 - val_loss: 1.2582\n",
      "Epoch 8/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6893 - loss: 1.0909 - val_accuracy: 0.6201 - val_loss: 1.1929\n",
      "Epoch 9/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7101 - loss: 0.9794 - val_accuracy: 0.6346 - val_loss: 1.1333\n",
      "Epoch 10/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7128 - loss: 0.9649 - val_accuracy: 0.6492 - val_loss: 1.0848\n",
      "Epoch 11/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7417 - loss: 0.8688 - val_accuracy: 0.6710 - val_loss: 1.0473\n",
      "Epoch 12/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7626 - loss: 0.8082 - val_accuracy: 0.6783 - val_loss: 1.0090\n",
      "Epoch 13/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7591 - loss: 0.7932 - val_accuracy: 0.6841 - val_loss: 0.9848\n",
      "Epoch 14/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7803 - loss: 0.7428 - val_accuracy: 0.6987 - val_loss: 0.9541\n",
      "Epoch 15/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7795 - loss: 0.7166 - val_accuracy: 0.6914 - val_loss: 0.9341\n",
      "Epoch 16/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7922 - loss: 0.6926 - val_accuracy: 0.6914 - val_loss: 0.9147\n",
      "Epoch 17/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7940 - loss: 0.6854 - val_accuracy: 0.6972 - val_loss: 0.8991\n",
      "Epoch 18/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8068 - loss: 0.6761 - val_accuracy: 0.7016 - val_loss: 0.8800\n",
      "Epoch 19/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8062 - loss: 0.6317 - val_accuracy: 0.7045 - val_loss: 0.8657\n",
      "Epoch 20/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8132 - loss: 0.6197 - val_accuracy: 0.7176 - val_loss: 0.8526\n",
      "Epoch 21/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8144 - loss: 0.6049 - val_accuracy: 0.7176 - val_loss: 0.8324\n",
      "Epoch 22/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8273 - loss: 0.5754 - val_accuracy: 0.7118 - val_loss: 0.8285\n",
      "Epoch 23/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8294 - loss: 0.5394 - val_accuracy: 0.7263 - val_loss: 0.8158\n",
      "Epoch 24/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8314 - loss: 0.5470 - val_accuracy: 0.7234 - val_loss: 0.8154\n",
      "Epoch 25/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8168 - loss: 0.5613 - val_accuracy: 0.7351 - val_loss: 0.7980\n",
      "Epoch 26/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8257 - loss: 0.5557 - val_accuracy: 0.7365 - val_loss: 0.7902\n",
      "Epoch 27/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8387 - loss: 0.5203 - val_accuracy: 0.7365 - val_loss: 0.7869\n",
      "Epoch 28/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8409 - loss: 0.5091 - val_accuracy: 0.7380 - val_loss: 0.7784\n",
      "Epoch 29/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8512 - loss: 0.4994 - val_accuracy: 0.7438 - val_loss: 0.7709\n",
      "Epoch 30/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8546 - loss: 0.4620 - val_accuracy: 0.7394 - val_loss: 0.7658\n",
      "Epoch 31/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8528 - loss: 0.4713 - val_accuracy: 0.7365 - val_loss: 0.7625\n",
      "Epoch 32/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8613 - loss: 0.4575 - val_accuracy: 0.7394 - val_loss: 0.7633\n",
      "Epoch 33/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8697 - loss: 0.4259 - val_accuracy: 0.7438 - val_loss: 0.7521\n",
      "Epoch 34/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8789 - loss: 0.4260 - val_accuracy: 0.7453 - val_loss: 0.7492\n",
      "Epoch 35/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8547 - loss: 0.4456 - val_accuracy: 0.7380 - val_loss: 0.7472\n",
      "Epoch 36/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8639 - loss: 0.4325 - val_accuracy: 0.7555 - val_loss: 0.7422\n",
      "Epoch 37/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8623 - loss: 0.4225 - val_accuracy: 0.7511 - val_loss: 0.7308\n",
      "Epoch 38/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8804 - loss: 0.4079 - val_accuracy: 0.7424 - val_loss: 0.7313\n",
      "Epoch 39/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8836 - loss: 0.3889 - val_accuracy: 0.7496 - val_loss: 0.7373\n",
      "Epoch 40/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8786 - loss: 0.3977 - val_accuracy: 0.7482 - val_loss: 0.7298\n",
      "Epoch 41/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8768 - loss: 0.3965 - val_accuracy: 0.7453 - val_loss: 0.7252\n",
      "Epoch 42/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8657 - loss: 0.3944 - val_accuracy: 0.7525 - val_loss: 0.7173\n",
      "Epoch 43/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8823 - loss: 0.3733 - val_accuracy: 0.7511 - val_loss: 0.7222\n",
      "Epoch 44/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8928 - loss: 0.3508 - val_accuracy: 0.7598 - val_loss: 0.7203\n",
      "Epoch 45/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8912 - loss: 0.3625 - val_accuracy: 0.7555 - val_loss: 0.7201\n",
      "Epoch 46/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8925 - loss: 0.3471 - val_accuracy: 0.7555 - val_loss: 0.7182\n",
      "Epoch 47/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8861 - loss: 0.3603 - val_accuracy: 0.7555 - val_loss: 0.7158\n",
      "Epoch 48/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9000 - loss: 0.3453 - val_accuracy: 0.7627 - val_loss: 0.7143\n",
      "Epoch 49/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8933 - loss: 0.3552 - val_accuracy: 0.7686 - val_loss: 0.7159\n",
      "Epoch 50/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9069 - loss: 0.3332 - val_accuracy: 0.7598 - val_loss: 0.7127\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Accuracy: 75.98%\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns=['muscleID']).values  # Features as a NumPy array\n",
    "y = df['muscleID'].values  # Target array\n",
    "\n",
    "# If target is categorical, convert it to one-hot encoding\n",
    "y = to_categorical(y)  # Converts integer labels to one-hot encoded labels\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform both training and test data\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Build the neural network model\n",
    "model = Sequential()\n",
    "\n",
    "# Add an input layer and a hidden layer with 64 neurons and 'relu' activation\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "\n",
    "# Add an output layer with softmax activation (assuming multiple classes)\n",
    "model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convert the predictions from one-hot encoding back to class labels\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test_classes, y_pred_classes)\n",
    "\n",
    "# Print the accuracy\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7614f95-0c97-47bb-b2a6-2152369127ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
